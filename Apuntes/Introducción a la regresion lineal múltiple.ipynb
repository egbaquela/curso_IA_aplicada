{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Lineal\n",
    "La regresión lineal es uno de los métodos mas antiguos de Aprendizaje Supervisado. La regresión lineal se basa en el principio subyacente que las variables independientes (predictores o features) se relacionan en forma lineal a efectos de generar el valor de la variable dependiente. Además de permitirnos predecir la variable independiente, también nos permite identificar cuales son las variables dependientes que mas impactan en el valor de la variable a predecir.\n",
    "\n",
    "## Modelo subyacente\n",
    "El modelo subycente a una regresión lineal consiste en una combinación lineal de todos los predictores:\n",
    "#### Modelo de regresión lineal simple (un predictor): \n",
    "\\begin{equation*}\n",
    "y = \\theta_{0} + \\theta_{1} \\cdot x_{1} + \\epsilon\n",
    "\\end{equation*}\n",
    "\n",
    "Con:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{y} = \\theta_{0} + \\theta_{1} \\cdot x{1}\n",
    "\\end{equation*}\n",
    "\n",
    "#### Modelo de regresión lineal múltiple (muchos predictores):\n",
    "\\begin{equation*}\n",
    "y = \\theta_{0} + \\sum_{i=1}^{n}(\\theta_{i} \\cdot x_{i}) + \\epsilon\n",
    "\\end{equation*}\n",
    "\n",
    "Con:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{y} = \\theta_{0} + \\sum_{i=1}^{n}(\\theta_{i} \\cdot x_{i}) \n",
    "\\end{equation*}\n",
    "\n",
    "Donde:\n",
    "- $\\hat{y}$ es el valor predicho (la estimación de la variable independiente).\n",
    "- $n$ es el número de variables dependientes.\n",
    "- $x_{i}$ es la $ith$ variable dependiente.\n",
    "- $\\theta_{j}$ es el $jth$ parámetro del modelo. Incluye el bias (sesgo o término independiente) y los coeficientes de todas las variables dependientes.\n",
    "- $\\epsilon$ es el error (aleatorio) en la predicción.\n",
    "\n",
    "Usualmente, en Machine Learning la notación anterior (notación normal) no es muy usada. Se prefiere la notación matricial porque permite expresiones mucho mas compactas:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{\\vec{y}} = \\vec{θ}^{T} \\cdot \\vec{X}\n",
    "\\end{equation*}\n",
    "\n",
    "Donde:\n",
    "- $\\vec{θ}$ es el vector fila de parámetros del modelo. Incluye el bias (sesgo o término independiente) y los coeficientes de todas las variables dependientes.\n",
    "- $\\vec{θ}^{T}$ es el transpuesto del vector fila $\\vec{θ}$ (o sea, un vector columna).\n",
    "- $\\vec{X}$ es el vector fila de variables independientes. Para poder multiplicarlo por $\\vec{θ}^{T}$, se agrega la componente inicial correspoendiente al bias ($\\theta_{0}$), la cual vale siempre $1$.\n",
    "- $\\vec{θ}^{T} \\cdot \\vec{X}$ es el producto matricial entre $\\vec{X}$ y $\\vec{θ}^{T}$.\n",
    "- $\\hat{y}$ es la predicción (un escalar).\n",
    "\n",
    "### Caracterización de un modelo de regresión lineal\n",
    "Ya sabida la forma en que se combinan los predictores, un modelo de regresión lineal se puede caracterizar completamente por $\\vec{θ}$. Es decir, a efectos de predecir el valor de $y$ (es decir, calcular $\\hat{y}$) solo necesitamos conocer $\\theta$ y multiplicar su transpuesto por el vector de los valores de los predictores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo (cálculo de $\\vec{\\theta}$)\n",
    "En un problema de Aprendizaje Supervisado, partimos de un conjunto de $m$ observaciones de parejas de $\\vec{X}$ e $y$. Recordemos que $\\vec{X}$ es un vector fila, entonces, colocando un vector $\\vec{X}$ abajo de otro podemos crear la matriz de observaciones $\\textbf{X}^{mx(n+1)}$ en el cual cada una de las $m$ filas es una observación (o muestra) y cada una de las $n+1$ columnas un predictor (la primera columna es la constante $1$). O sea, si tenemos:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\vec{X}^{1} = (x_{1}^{1}, x_{2}^{1}, \\cdots  , x_{n}^{1})  \\\\\n",
    "\\vec{X}^{2} = (x_{1}^{2}, x_{2}^{2}, \\cdots  , x_{n}^{2})  \\\\\n",
    "\\vdots  \\\\\n",
    "\\vec{X}^{m} = (x_{1}^{m}, x_{2}^{m}, \\cdots  , x_{n}^{m})  \\\\\n",
    "\\end{equation*}\n",
    "\n",
    "Podemos escribirlo en forma matricial como:\n",
    "\\begin{equation*}\n",
    "\\textbf{X} = \n",
    "  \\begin{bmatrix}\n",
    "    1 & x_{1}^{1} & x_{2}^{1} & \\cdots & x_{n}^{1} \\\\\n",
    "    1 & x_{1}^{2} & x_{2}^{2} & \\cdots & x_{n}^{2} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    1 & x_{1}^{m} & x_{2}^{m} & \\cdots & x_{n}^{m} \\\\\n",
    "  \\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "En forma similar, podemos transformar las $m$ observaciones de $y$ en un vector columna $\\vec{y}$ de $m$ dimensiones:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\vec{y} = \n",
    "  \\begin{bmatrix}\n",
    "    y^{1} \\\\\n",
    "    y^{2} \\\\\n",
    "    \\vdots \\\\\n",
    "    y^{m} \\\\\n",
    "  \\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Por las definiciones dadas en la sección anterior, $\\vec{y}$ es equivalente a:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\vec{y} = \\vec{\\hat{y}} + \\vec{e} = \\textbf{X}\\vec{\\theta}^{T} + \\vec{\\epsilon}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "O en su forma explícita:\n",
    "\n",
    "\\begin{equation*}\n",
    " \\begin{bmatrix}\n",
    "    y^{1} \\\\\n",
    "    y^{2} \\\\\n",
    "    \\vdots \\\\\n",
    "    y^{m} \\\\\n",
    " \\end{bmatrix}  \n",
    " = \n",
    " \\begin{bmatrix}\n",
    "    1 & x_{1}^{1} & x_{2}^{1} & \\cdots & x_{n}^{1} \\\\\n",
    "    1 & x_{1}^{2} & x_{2}^{2} & \\cdots & x_{n}^{2} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    1 & x_{1}^{m} & x_{2}^{m} & \\cdots & x_{n}^{m} \\\\\n",
    " \\end{bmatrix}\n",
    " \\begin{bmatrix}\n",
    "     \\theta_{0} \\\\\n",
    "     \\theta_{1} \\\\\n",
    "     \\theta_{2} \\\\ \n",
    "     \\cdots \\\\\n",
    "     \\theta_{n}\n",
    " \\end{bmatrix} \n",
    " +\n",
    " \\begin{bmatrix}\n",
    "    \\epsilon^{1} \\\\\n",
    "    \\epsilon^{2} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\epsilon^{m} \\\\\n",
    " \\end{bmatrix}  \n",
    "\\end{equation*}\n",
    "\n",
    "Donde $\\vec{\\epsilon}$ es el vector de los errores o diferencias de cada valor predicho respecto del valor muestreado. Siendo $\\vec{y}$ y $\\textbf{X}$ datos, queremos encontrar el valor de $\\vec{\\theta}$ que nos permite minimizar $\\vec{\\epsilon}$. Desde Gauss en adelante, se sabe (lo demostró el alemán) que el mejor escalar que minimiza $\\vec{\\epsilon}$ es la suma de sus errores cuadráticos, entonces nuestra función de costo se puede expresar como:\n",
    "\n",
    "\\begin{equation*}\n",
    "J(\\vec{\\theta}|(\\textbf{X}, \\vec{y}))= \\sum_{i=1}^{m} [(\\epsilon_{i})^{2}] \n",
    "\\end{equation*}\n",
    "\n",
    "Siendo el problema de optimización a resolver:\n",
    "\n",
    "\\begin{equation*}\n",
    "Min\\ J(\\vec{\\theta}|(\\textbf{X}, \\vec{y}))\n",
    "\\end{equation*}\n",
    "\n",
    "En realidad, para que la minimización de $\\sum_{i=1}^{m} [(\\epsilon_{i})^{2}] $ sea la que nos permite obtener el mejor vector $\\vec{\\theta}$ posible, se deben cumplir una serie de hipótesis:\n",
    "\n",
    " - Esperanza matemática nula de los errores: $E(\\epsilon) = 0 $. Es decir, los valores de $\\epsilon$ seran aleatorios, pero no tomaran sistematicamente valores positivos o negativos.\n",
    " - Homocedasticidad: $Var(\\epsilon) = E(\\epsilon - E(\\epsilon))^2 = E(\\epsilon)^2 = \\sigma^{2}$. La varianza del error es siempre la misma (aunque es desconocida).\n",
    " - Incorrelación o independencia: . El valor de ningún elemento muestral está influenciado por el valor de ningún otro.\n",
    " - Regresores estocásticos: la muestra se tomó en forma aleatoria.\n",
    " - Independencia lineal. No existen relaciones lineales exactas entre los regresores.\n",
    " - Normalidad de las perturbaciones: $\\epsilon \\sim N(0, \\sigma^2)$. Los errores se distribuyen en forma estable según una distribución normal de media $0$ y desviación estandar $\\sigma$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo exacto de $\\vec{\\theta}$\n",
    "Asumiendo que se cumplen las hipótesis requeridas y el determinante de $\\textbf{X}^{T}\\textbf{X}$ es no nulo, la solución del problema de minimización es:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\vec{\\theta} = (\\textbf{X}^{T}\\textbf{X})^{-1}\\textbf{X}^{T}\\vec{y}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generemos nuestro primer ejemplo de regresion lineal simple. Importemos Numpy y creemos datos aleatorios para $\\textbf{X}$ (en este caso, como tenemos un solo predictor, sería un vector fila $\\vec{X}$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(19680801) # Fijo la semilla aleatoria, para reproducir el experimento\n",
    "X = 2 * np.random.rand(100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el contenido de las primeras 10 muestras de nuestra variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.40073461],\n",
       "       [ 1.48550162],\n",
       "       [ 1.41856002],\n",
       "       [ 1.13349104],\n",
       "       [ 1.95557067],\n",
       "       [ 1.41266969],\n",
       "       [ 0.49583152],\n",
       "       [ 0.3157667 ],\n",
       "       [ 1.39539704],\n",
       "       [ 1.43991333]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta visualización no es tan útil, hagamos un histograma con matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_bins = 20\n",
    "plt.title('Variable Independiente')\n",
    "plt.hist(X, bins = n_bins)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos $y$ como una función lineal respecto de $\\textbf{X}$ pero con ruido aleatorio. Obviamente, en un ejemplo real no conocería la forma de $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 4 + 3 * X + np.random.randn(100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos como lucen los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, y, \"b.\") #\"b.\" indica que grafique puntos sin unir mediente líneas\n",
    "plt.axis([0, 2, 0, 15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple vista se observa cierta dependencia. Pero supongamos que no sabemos como está definida \"y\" y tratemos de estimarla usando regresión lineal.\n",
    "Primero, agreguemos a los datos el coefiente 1 para el término independiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b = np.c_[np.ones((100, 1)), X] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora calculemos los valores de θ que minimizan el error en el ajuste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.02504519],\n",
       "       [ 2.97242573]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y) \n",
    "#\".T\" calcula la transpuesta de una matriz, \n",
    "#\".dot\" el producto matricial, \n",
    "#\"linalg\" es el conjunto de funciones para álgebra lineal\n",
    "#\"inv\" calcula la inversa de la matriz pasada como parámetro\n",
    "theta_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listo, theta_best son los parámetros del modelo de regresión lineal que ajusté que minimizan el error (que lo definimos aleatoriamente). ¿Como uso theta_best para hacer una predicción?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.02504519],\n",
       "       [ 9.96989666]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array([[0], [2]])\n",
    "X_new_b = np.c_[np.ones((2, 1)), X_new] # añade x0 = 1 a cada instancia. \n",
    "y_predict = X_new_b.dot(theta_best)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo grafico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_new, y_predict, \"r-\")\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.axis([0, 2, 0, 15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculo de $\\theta$ mediante \"*Descenso por gradiente*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Mostrar como evoluciona el costo $J(\\theta,X)$ a medida que avanza el algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacer el cálculo \"manual\" funciona bien, pero el paquete \"Scikit-Learn\" es una mejor alternativa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.02504519]), array([[ 2.97242573]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora la predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = lin_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.02504519],\n",
       "       [ 9.96989666]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usos típicos de la regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: ejemplos de uso típicos en los cuales me conviene usar regresión lineal por sobre otro tipo de modelo.\n",
    "Adjuntar links a videos/documentación/bibliografía."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografía"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: incluir videos y cursos online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
